{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of pipeline execution time across different branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_REAL_DATA = False\n",
    "USE_OLD_PIPELINE_RUNS = False\n",
    "\n",
    "if USE_REAL_DATA:\n",
    "    DB_NAME = 'openpath_prod_nrel_commute'\n",
    "    HISTORICAL_DAYS = [\n",
    "        # ('2024-11-01', '2024-12-01'),\n",
    "        # ('2024-12-01', '2025-01-01'),\n",
    "        # ('2025-01-01', '2025-02-01'),\n",
    "    ]\n",
    "    OPCODE = 'nrelop_nrel-commute_fYsciV5vttojUzmWBouIhSjwacQeerdzjc3EauETcVKzc'\n",
    "    REAL_EXAMPLES = None\n",
    "else:\n",
    "    DB_NAME = None\n",
    "    OPCODE = 'nrelop_dev-emulator-study_0'\n",
    "    REAL_EXAMPLES = [\n",
    "        # \"shankari_2016-06-20\",\n",
    "        # \"shankari_2016-07-25\",\n",
    "        \"shankari_2016-07-27\",\n",
    "        # \"shankari_2016-08-04\",\n",
    "    ]\n",
    "\n",
    "BRANCHES = [\n",
    "    # '47ab8be28a1682f841b3d6a03cbe0f9fe0515e0f',\n",
    "    # 'vectorized_segmentation',\n",
    "    # 'remove_invalid_query',\n",
    "    # 'master',\n",
    "    # 'section_segmentation_db_optimize',\n",
    "    # 'batch_overpass'\n",
    "    'RM_Direct_DBCalls',\n",
    "    'master'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies for this notebook that aren't already in the 'emission' environment\n",
    "!pip install plotly\n",
    "!pip install nbformat\n",
    "\n",
    "if DB_NAME:\n",
    "    %env DB_HOST=mongodb://localhost:27017/$DB_NAME\n",
    "%env MONITOR_DB=True\n",
    "%env USE_HINTS=True\n",
    "%env DB_RESULT_LIMIT=5000000\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import plotly.express as px\n",
    "import emission.core.get_database as edb\n",
    "import emission.core.timer as ect\n",
    "import emission.core.wrapper.user as ecwu\n",
    "import emission.storage.decorations.stats_queries as esds\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.timeseries.timequery as estt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGES = {\n",
    "    'USERCACHE': 'moveToLongTerm',\n",
    "    'USER_INPUT_MATCH_INCOMING': 'match_incoming_user_inputs',\n",
    "    'ACCURACY_FILTERING': 'filter_accuracy',\n",
    "    'TRIP_SEGMENTATION': 'segment_current_trips',\n",
    "    'SECTION_SEGMENTATION': 'segment_current_sections',\n",
    "    'JUMP_SMOOTHING': 'filter_current_sections',\n",
    "    'CLEAN_RESAMPLING': 'clean_and_resample',\n",
    "    'MODE_INFERENCE': 'predict_mode',\n",
    "    'LABEL_INFERENCE': 'infer_labels',\n",
    "    'EXPECTATION_POPULATION': 'populate_expectations',\n",
    "    'CREATE_CONFIRMED_OBJECTS': 'create_confirmed_objects',\n",
    "    'CREATE_COMPOSITE_OBJECTS': 'create_composite_objects',\n",
    "    'STORE_PIPELINE_DEPENDENT_USER_STATS': 'get_and_store_pipeline_dependent_user_stats',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REAL_EXAMPLES:\n",
    "    print(f\"Loading {REAL_EXAMPLES} for {OPCODE}\")\n",
    "    !./e-mission-py.bash bin/debug/purge_user.py -e $OPCODE\n",
    "    for DAY in REAL_EXAMPLES:\n",
    "        !./e-mission-py.bash bin/debug/load_timeline_for_day_and_user.py emission/tests/data/real_examples/$DAY $OPCODE\n",
    "\n",
    "def run_intake_on_branch(branch_name, intake_stat_name):\n",
    "    curr_branch_name_name = subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD']).decode('utf-8').strip()\n",
    "    print(f\"Checking out {branch_name} to measure pipeline runtime\")\n",
    "    !git checkout $branch_name\n",
    "    with ect.Timer() as t:\n",
    "        if OPCODE:\n",
    "            !./e-mission-py.bash ./bin/reset_pipeline.py -e $OPCODE\n",
    "            !./e-mission-py.bash bin/debug/intake_single_user.py -e $OPCODE\n",
    "        else:\n",
    "            !./e-mission-py.bash ./bin/reset_pipeline.py --all\n",
    "            !./e-mission-py.bash bin/intake_multiprocess.py 3\n",
    "    assert t.elapsed > 1\n",
    "    end_ts = time.time()\n",
    "    start_ts = end_ts - t.elapsed\n",
    "    esds.store_pipeline_time(ecwu.User.fromEmail(OPCODE).uuid if OPCODE else None,\n",
    "                             intake_stat_name,\n",
    "                             end_ts,\n",
    "                             t.elapsed)\n",
    "    print(f\"Ran pipeline on {branch_name} from {start_ts} to {end_ts}\")\n",
    "    print(f\"Switching back to {curr_branch_name_name}\")\n",
    "    !git checkout $curr_branch_name_name\n",
    "    return (start_ts, end_ts)\n",
    "\n",
    "ts = esta.TimeSeries.get_aggregate_time_series()\n",
    "\n",
    "pipeline_stats_dfs = []\n",
    "if USE_REAL_DATA and HISTORICAL_DAYS:\n",
    "    for (START_DAY, END_DAY) in HISTORICAL_DAYS:\n",
    "        start_ts = datetime.datetime.strptime(START_DAY, '%Y-%m-%d').timestamp()\n",
    "        end_ts = datetime.datetime.strptime(END_DAY, '%Y-%m-%d').timestamp()\n",
    "        tq = estt.TimeQuery('data.ts', start_ts, end_ts)\n",
    "        df = ts.get_data_df('stats/pipeline_time', time_query=tq).assign(branch=f'{START_DAY} to {END_DAY}')\n",
    "        pipeline_stats_dfs.append(df)\n",
    "else:\n",
    "    for branch_name in BRANCHES:\n",
    "        commit_hash = subprocess.check_output(['git', 'rev-parse', branch_name]).decode('utf-8').strip()\n",
    "        intake_stat_name = f'INTAKE/{commit_hash}/{DB_NAME}/{OPCODE or \"all\"}'\n",
    "        intake_stats = list(edb.get_timeseries_db().find({ 'data.name': intake_stat_name }).sort('_id', -1).limit(1))\n",
    "        if USE_OLD_PIPELINE_RUNS and intake_stats:\n",
    "            start_ts = intake_stats[0]['data']['ts'] - intake_stats[0]['data']['reading']\n",
    "            end_ts = intake_stats[0]['data']['ts']\n",
    "            print(f\"Using previous pipeline run on {branch_name}: at commit {commit_hash}, from {start_ts} to {end_ts}\")\n",
    "        else:\n",
    "            (start_ts, end_ts) = run_intake_on_branch(branch_name, intake_stat_name)\n",
    "        tq = estt.TimeQuery('data.ts', start_ts, end_ts)\n",
    "        df = ts.get_data_df('stats/pipeline_time', time_query=tq).assign(branch=branch_name)\n",
    "        pipeline_stats_dfs.append(df)\n",
    "\n",
    "pipeline_stats_df = pd.concat(pipeline_stats_dfs).reset_index(drop=True)\n",
    "pipeline_stages_df = pipeline_stats_df[pipeline_stats_df['name'].isin(STAGES.keys())]\n",
    "\n",
    "def get_stage(row):\n",
    "    for stage, fn_name in STAGES.items():\n",
    "        if row['name'].startswith(stage):\n",
    "            return stage\n",
    "        if isinstance(row['reading'], str) and fn_name in row['reading']:\n",
    "            return stage\n",
    "    return None\n",
    "pipeline_stats_df['stage'] = pipeline_stats_df.apply(get_stage, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runtimes(df, color='branch', pattern_shape=None, x='reading', y='name', barmode='group', title='Pipeline runtimes'):\n",
    "    if df.empty: return print(f'No {title}')\n",
    "    \n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    fig = px.bar(\n",
    "        df,\n",
    "        y=y,\n",
    "        x=x,\n",
    "        color=color,\n",
    "        orientation=\"h\",\n",
    "        hover_data=['user_id']\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"{title}<br>({REAL_EXAMPLES or DB_NAME})\",\n",
    "        barmode=barmode,\n",
    "        legend=dict(yref=\"container\", xanchor=\"right\", x=1, y=0),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_db_calls_by_stage(db_calls_df, title='DB calls'):\n",
    "    if db_calls_df.empty: return print(f'No {title}')\n",
    "    \n",
    "    db_calls_counts_df = db_calls_df.groupby(['stage', 'name', 'reading'])['branch'].value_counts(sort=False).reset_index(name='count')\n",
    "    # display(db_calls_counts_df.sort_values(['count'], ascending=False))\n",
    "    db_calls_counts_df['reading_wrapped'] = db_calls_counts_df['reading'].str.replace(',', '<br>')\n",
    "    fig = px.bar(\n",
    "        db_calls_counts_df,\n",
    "        y='stage',\n",
    "        x='count',\n",
    "        color='branch',\n",
    "        orientation=\"h\",\n",
    "        hover_data=['name', 'reading_wrapped'],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"{title}<br>({REAL_EXAMPLES or DB_NAME})\",\n",
    "        barmode='group',\n",
    "        xaxis=dict(title=\"# DB calls\"),\n",
    "        legend=dict(yref=\"container\", xanchor=\"right\", x=1, y=0),\n",
    "    )\n",
    "    fig.show()\n",
    "    return db_calls_counts_df\n",
    "\n",
    "\n",
    "def plot_db_calls_by_name(db_calls_df, title='DB calls'):\n",
    "    if db_calls_df.empty: return print(f'No {title}')\n",
    "\n",
    "    db_calls_counts_df = db_calls_df.groupby(['name', 'reading'])['branch'].value_counts(sort=False).reset_index(name='count')\n",
    "    db_calls_counts_df['reading_wrapped'] = db_calls_counts_df['reading'].str.replace(',', '<br>')\n",
    "    fig = px.bar(\n",
    "        db_calls_counts_df,\n",
    "        y='name',\n",
    "        x='count',\n",
    "        color='branch',\n",
    "        orientation=\"h\",\n",
    "        hover_data=['reading_wrapped'],\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"{title}<br>({REAL_EXAMPLES or DB_NAME})\",\n",
    "        barmode='group',\n",
    "        xaxis=dict(title=\"# DB calls\"),\n",
    "        legend=dict(yref=\"container\", xanchor=\"right\", x=1, y=0),\n",
    "    )\n",
    "    fig.show()\n",
    "    return db_calls_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runtimes(\n",
    "    pipeline_stages_df,\n",
    "    y='branch',\n",
    "    color='branch',\n",
    "    pattern_shape='name',\n",
    "    barmode='stack',\n",
    "    title='Pipeline runtimes, overall',\n",
    ")\n",
    "\n",
    "plot_runtimes(\n",
    "    pipeline_stages_df,\n",
    "    title='Pipeline runtimes by stage',\n",
    ")\n",
    "\n",
    "df = plot_db_calls_by_name(\n",
    "    pipeline_stats_df[pipeline_stats_df['name'].str.startswith('db_call/')],\n",
    "    title='DB calls during pipeline (all types)'\n",
    ")\n",
    "display(df[(df['name'] == 'db_call/createIndexes') & (df['branch'] == 'master')][['reading', 'count']])\n",
    "\n",
    "\n",
    "plot_db_calls_by_stage(\n",
    "    pipeline_stats_df[pipeline_stats_df['name'].str.startswith('db_call/')],\n",
    "    title='DB calls during pipeline by stage (all types)'\n",
    ")\n",
    "\n",
    "NON_INDEX_DB_CMDS = ['find', 'aggregate', 'insert', 'update', 'delete']\n",
    "\n",
    "plot_db_calls_by_name(\n",
    "    pipeline_stats_df[\n",
    "        pipeline_stats_df['name'].isin([f'db_call/{n}' for n in NON_INDEX_DB_CMDS])\n",
    "    ],\n",
    "    title=f'DB calls during pipeline ({NON_INDEX_DB_CMDS})'\n",
    ")\n",
    "\n",
    "plot_db_calls_by_stage(\n",
    "    pipeline_stats_df[\n",
    "        pipeline_stats_df['name'].isin([f'db_call/{n}' for n in NON_INDEX_DB_CMDS])\n",
    "    ],\n",
    "    title=f'DB calls during pipeline by stage ({NON_INDEX_DB_CMDS})'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in [\n",
    "    # 'USERCACHE',\n",
    "    # 'USER_INPUT_MATCH_INCOMING',\n",
    "    # 'ACCURACY_FILTERING',\n",
    "    # 'TRIP_SEGMENTATION',\n",
    "    # 'SECTION_SEGMENTATION',\n",
    "    'JUMP_SMOOTHING',\n",
    "    'CLEAN_RESAMPLING',\n",
    "    # 'MODE_INFERENCE',\n",
    "    # 'LABEL_INFERENCE',\n",
    "    # 'EXPECTATION_POPULATION',\n",
    "    # 'CREATE_CONFIRMED_OBJECTS',\n",
    "    # 'CREATE_COMPOSITE_OBJECTS',\n",
    "    # 'STORE_PIPELINE_DEPENDENT_USER_STATS',\n",
    "]:\n",
    "    plot_runtimes(\n",
    "        pipeline_stages_df[pipeline_stages_df['name'] == stage],\n",
    "        title=f'Pipeline runtimes of {stage}'\n",
    "    )\n",
    "\n",
    "    plot_runtimes(\n",
    "        pipeline_stats_df[pipeline_stats_df['name'].str.match(f'{stage}/')],\n",
    "        title=f'Substage runtimes of {stage}',\n",
    "    )\n",
    "\n",
    "    plot_db_calls_by_stage(\n",
    "        pipeline_stats_df[\n",
    "            (pipeline_stats_df['name'].str.startswith('db_call/'))\n",
    "            & (pipeline_stats_df['reading'].str.contains(STAGES[stage]))\n",
    "        ],\n",
    "        title=f'DB calls during {stage} (all types)',\n",
    "    )\n",
    "\n",
    "    plot_db_calls_by_stage(\n",
    "        pipeline_stats_df[\n",
    "            (pipeline_stats_df['name'].isin([f'db_call/{n}' for n in NON_INDEX_DB_CMDS]))\n",
    "            & (pipeline_stats_df['reading'].str.contains(STAGES[stage]))\n",
    "        ],\n",
    "        title=f'DB calls during {stage} (all types)',\n",
    "    )\n",
    "\n",
    "    plot_db_calls_by_name(\n",
    "        pipeline_stats_df[\n",
    "            (pipeline_stats_df['name'].str.startswith('db_call/'))\n",
    "            & (pipeline_stats_df['reading'].str.contains(STAGES[stage]))\n",
    "        ],\n",
    "        title=f'DB calls during {stage} (all types)'\n",
    "    )\n",
    "\n",
    "    plot_db_calls_by_name(\n",
    "        pipeline_stats_df[\n",
    "            (pipeline_stats_df['name'].isin([f'db_call/{n}' for n in NON_INDEX_DB_CMDS]))\n",
    "            & (pipeline_stats_df['reading'].str.contains(STAGES[stage]))\n",
    "        ],\n",
    "        title=f'DB calls during {stage} ({NON_INDEX_DB_CMDS})'\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
