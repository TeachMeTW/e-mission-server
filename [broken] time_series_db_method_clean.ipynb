{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DB_HOST=mongodb://localhost/openpath_prod_ccebikes\n",
      "env: DB_RESULT_LIMIT=1000000\n",
      "Config file not found, returning a copy of the environment variables instead...\n",
      "Retrieved config: {'DB_HOST': 'mongodb://localhost/openpath_prod_ccebikes', 'DB_RESULT_LIMIT': '1000000'}\n",
      "Connecting to database URL mongodb://localhost/openpath_prod_ccebikes\n"
     ]
    }
   ],
   "source": [
    "%env DB_HOST=mongodb://localhost/openpath_prod_ccebikes\n",
    "%env DB_RESULT_LIMIT=1000000\n",
    "import emission.core.get_database as edb\n",
    "#import emission.storage.timeseries.aggregate_timeseries as esta\n",
    "import emission.storage.timeseries.builtin_timeseries as estb\n",
    "import emission.core.get_database as gdb\n",
    "\n",
    "# Import necessary libraries and modules\n",
    "import emission.core.get_database as edb\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.timeseries.builtin_timeseries as estb\n",
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import emission.core.wrapper.entry as ecwe\n",
    "import emission.storage.decorations.trip_queries as esdt\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 11:18:06,478 - root - DEBUG - curr_query = {'invalid': {'$exists': False}, '$or': [{'metadata.key': 'stats/pipeline_time'}], 'data.name': 'STORE_USER_STATS'}, sort_key = None\n",
      "2024-12-09 11:18:06,480 - root - DEBUG - orig_ts_db_keys = ['stats/pipeline_time'], analysis_ts_db_keys = []\n",
      "2024-12-09 11:18:08,350 - root - DEBUG - finished querying values for ['stats/pipeline_time'], count = 1064\n",
      "2024-12-09 11:18:08,351 - root - DEBUG - finished querying values for [], count = 0\n",
      "2024-12-09 11:18:08,353 - root - DEBUG - orig_ts_db_matches = 1064, analysis_ts_db_matches = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest Entry:\n",
      "_id                                    672b9a210783e03ac9b30f7c\n",
      "user_id                    6f836860-8b7b-4e1e-940f-7c6eb2e793e3\n",
      "key                                         stats/pipeline_time\n",
      "platform                                                 server\n",
      "write_ts                                      1730910753.231596\n",
      "time_zone                                   America/Los_Angeles\n",
      "write_fmt_time                 2024-11-06T08:32:33.231596-08:00\n",
      "write_local_dt.year                                        2024\n",
      "write_local_dt.month                                         11\n",
      "write_local_dt.day                                            6\n",
      "write_local_dt.hour                                           8\n",
      "write_local_dt.minute                                        32\n",
      "write_local_dt.second                                        33\n",
      "write_local_dt.weekday                                        2\n",
      "write_local_dt.timezone                     America/Los_Angeles\n",
      "name                                           STORE_USER_STATS\n",
      "ts                                            1730910753.231509\n",
      "reading                                                0.083887\n",
      "write_ts_dt                       2024-11-06 16:32:33.231595520\n",
      "Name: 4, dtype: object\n",
      "\n",
      "Latest Entry:\n",
      "_id                                    67547ad35a4dc318a65a8d47\n",
      "user_id                    6f836860-8b7b-4e1e-940f-7c6eb2e793e3\n",
      "key                                         stats/pipeline_time\n",
      "platform                                                 server\n",
      "write_ts                                      1733589715.354374\n",
      "time_zone                                   America/Los_Angeles\n",
      "write_fmt_time                 2024-12-07T08:41:55.354374-08:00\n",
      "write_local_dt.year                                        2024\n",
      "write_local_dt.month                                         12\n",
      "write_local_dt.day                                            7\n",
      "write_local_dt.hour                                           8\n",
      "write_local_dt.minute                                        41\n",
      "write_local_dt.second                                        55\n",
      "write_local_dt.weekday                                        5\n",
      "write_local_dt.timezone                     America/Los_Angeles\n",
      "name                                           STORE_USER_STATS\n",
      "ts                                            1733589715.354316\n",
      "reading                                                0.036498\n",
      "write_ts_dt                       2024-12-07 16:41:55.354374400\n",
      "Name: 1062, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ts = esta.TimeSeries.get_aggregate_time_series()\n",
    "#df = ts.get_data_df(\n",
    "#                \"stats/pipeline_time\")\n",
    "\n",
    "df2 = list(ts.find_entries([\"stats/pipeline_time\"], extra_query_list=[{\"data.name\": \"STORE_USER_STATS\"}]))\n",
    "\n",
    "df=pd.DataFrame(df2)\n",
    "# Flatten 'metadata' and 'data' fields\n",
    "if 'metadata' in df.columns:\n",
    "    metadata_expanded = pd.json_normalize(df['metadata'])\n",
    "    df = pd.concat([df.drop(columns=['metadata']), metadata_expanded], axis=1)\n",
    "\n",
    "if 'data' in df.columns:\n",
    "    data_expanded = pd.json_normalize(df['data'])\n",
    "    df = pd.concat([df.drop(columns=['data']), data_expanded], axis=1)\n",
    "\n",
    "#print(df)\n",
    "\n",
    "if 'write_ts' in df.columns:\n",
    "    df['write_ts_dt'] = pd.to_datetime(df['write_ts'], unit='s')\n",
    "\n",
    "# Find the earliest and latest entries\n",
    "earliest_entry = df.loc[df['write_ts'].idxmin()]\n",
    "latest_entry = df.loc[df['write_ts'].idxmax()]\n",
    "\n",
    "# Display the results\n",
    "print(\"Earliest Entry:\")\n",
    "print(earliest_entry)\n",
    "\n",
    "print(\"\\nLatest Entry:\")\n",
    "print(latest_entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
